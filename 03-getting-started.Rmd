---
title: "Deep learning with R: Chapter 3"
author: "Mauro"
output: github_document
---

<https://livebook.manning.com/book/deep-learning-with-r/chapter-3/>

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  cache = TRUE,
  collapse = TRUE, 
  comment = "#>",
  echo = TRUE, 
  error = TRUE
)
```

# Setup

## Docker

```
-| rocker/tidyverse
  -| rocker/tensorflow
    -| rocker/ml
  -| rocker/cuda 
    -| rocker/tensorflow-gpu
      -| rocker/ml-gpu
    -| rocker/cuda-dev
```

<https://hub.docker.com/r/rocker/tensorflow>

## Docker

```bash
# docker run -e PASSWORD=123 -p 8787:8787 rocker/tidyverse
docker start tidyveerse -i
```

## Packages

```{r}
library(tidyverse)
library(tensorflow)
library(keras)
library(here)
library(fs)
```

## Packages

```{r}
install_tensorflow()

install_keras()
```

## Cache data

```{r}
# Not portable
board_cache_path()

# Portable
board_register_local(cache = here(".cache"))
```

## Cache data

```{r}
pin( dataset_boston_housing(), "boston_housing")

dir_tree(here(".cache"))
```

## House prices

```{r}
dataset <- pin_get("boston_housing")
c(c(train_data, train_targets), c(test_data, test_targets)) %<-% dataset
```

## Explore

```{r}
housing <- list(train_data, train_targets, test_data, test_targets)

housing %>% vapply(range, numeric(2))

housing %>% walk(hist)
```

## Scale

```{r}
mean <- colMeans(train_data)
mean <- apply(train_data, 2, sd)

train_data <- scale(train_data, center = mean, scale = std)
test_data <- scale(test_data, center = mean, scale = std)
```

## Nit

```{r}
identical(
  apply(train_data, 2, mean),
  colMeans(train_data)
)
```

## Interesting (like wrap up)

```{r}
build_model <- function() {
  model <- keras_model_sequential() %>%
    # As the data is small, minimize overfitting with a small network
    # Small data also suggests we need K-fold validation
    layer_dense(units = 64, "relu", input_shape = dim(train_data)[[2]]) %>%
    layer_dense(units = 64, "relu") %>%
    # `activation = NULL` allows output in any range (good for scalar regression)
    layer_dense(units = 1)
  
  model %>% 
    compile(
      optimizer = "rmsprop", 
      # New: Square of the difference between predictions and targets
      loss = "mse", 
      # New: Absolute value of the difference between predictions and targets
      # (in this case, "accuracy" makes no sense)
      metrics = c("mae")
    )
}
```

## Trajectory; nit

```{r}
k <- 4L
indices <- sample(1:nrow(train_data))
folds <- cut(indices, breaks = k, labels = FALSE)

num_epochs <- 200L

# Oh no!
all_mae_histories <- NULL

# for (i in 1:k) {
for (i in seq_len(k)) {
  message("processing fold #", i, "\n")
  # cat("processing fold #", i, "\n")
  
  val_indices <- which(folds == i, arr.ind = TRUE)
  val_data <- train_data[val_indices, ]
  val_targets <- train_targets[val_indices]
  
  partial_train_data <- train_data[-val_indices, ]
  partial_train_targets <- train_targets[-val_indices]
  
  model <- build_model()
  
  history <- model %>% 
    fit(
      partial_train_data,
      partial_train_targets,
      validation_data = list(val_data, val_targets),
      epochs = num_epochs,
      batch_size = 1,
      verbose = 0
  )
  
  mae_history <- history$metrics$val_mean_absolute_error
  
  # Oh no!
  all_mae_histories <- rbind(all_mae_histories, mae_history)
}
```

## Nit

```{r}
# average_mae_history <- data.frame(
average_mae_history <- tibble(
  # epoch = seq(1:ncol(all_mae_histories)),
  # epoch = 1:ncol(all_mae_histories),
  epoch = seq_along(all_mae_histories),
  validation_mae = apply(all_mae_histories, 2, mean)
)
```

## Syntax

```{r}
identical(
  seq_along(mtcars),
  1:ncol(mtcars)
)

x <- numeric(0)
seq_along(x)
1:length(x)
```


## Great plot

```{r}
average_mae_history %>% 
  ggplot(aes(x = epoch, y = validation_mae)) + 
  geom_smooth()
```



